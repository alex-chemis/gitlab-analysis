"""
–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –º–∞—Å—à—Ç–∞–±–∞ –ø—Ä–æ–µ–∫—Ç–æ–≤ –ø–æ —è–∑—ã–∫–∞–º –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è
–û–¢–ù–û–°–ò–¢–ï–õ–¨–ù–ê–Ø –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø - –¥–µ–ª–∏—Ç —è–∑—ã–∫–∏ –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—è–º
"""

import argparse
from collections import defaultdict
from statistics import median
from typing import Dict, List, Tuple
import logging

from scripts.common.mongo import iter_projects
from scripts.common.plot import barh_chart

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def analyze_project_scale():
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–∞—Å—à—Ç–∞–± –ø—Ä–æ–µ–∫—Ç–æ–≤ –ø–æ —è–∑—ã–∫–∞–º –∏—Å–ø–æ–ª—å–∑—É—è —Ä–µ–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    """
    logger.info("üèóÔ∏è  –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –º–∞—Å—à—Ç–∞–±–∞ –ø—Ä–æ–µ–∫—Ç–æ–≤...")

    metrics = {
        'stars': defaultdict(list),
        'forks': defaultdict(list),
        'issues': defaultdict(list)
    }

    total_projects = 0
    projects_analyzed = 0

    for p in iter_projects({"languages": 1, "star_count": 1, "forks_count": 1, "open_issues_count": 1}):
        total_projects += 1

        languages = p.get("languages", {})
        if not languages:
            continue

        star_count = p.get("star_count", 0) or 0
        forks_count = p.get("forks_count", 0) or 0
        issues_count = p.get("open_issues_count", 0) or 0

        projects_analyzed += 1

        for lang in languages.keys():
            metrics['stars'][lang].append(int(star_count))
            metrics['forks'][lang].append(int(forks_count))
            metrics['issues'][lang].append(int(issues_count))

    logger.info(f"üìà –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    logger.info(f"  –í—Å–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–æ–≤ –≤ –±–∞–∑–µ: {total_projects}")
    logger.info(f"  –ü—Ä–æ–µ–∫—Ç–æ–≤ —Å –ø–æ–ª–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏: {projects_analyzed}")
    logger.info(f"  –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —è–∑—ã–∫–æ–≤: {len(metrics['stars'])}")

    return metrics


def calculate_relative_composite_score(stars_median: float, forks_median: float, issues_median: float,
                                     all_scores: List[float]) -> Tuple[float, str]:
    """
    –û–¢–ù–û–°–ò–¢–ï–õ–¨–ù–ê–Ø –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è - –¥–µ–ª–∏—Ç —è–∑—ã–∫–∏ –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—è–º
    """
    # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ–º–ø–æ–∑–∏—Ç–Ω—É—é –æ—Ü–µ–Ω–∫—É (–ø—Ä–æ—Å—Ç–∞—è —Å—É–º–º–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π)
    composite = (stars_median * 0.4 + forks_median * 0.35 + issues_median * 0.25)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –û–¢–ù–û–°–ò–¢–ï–õ–¨–ù–û –¥—Ä—É–≥–∏—Ö —è–∑—ã–∫–æ–≤
    if not all_scores:
        return composite, "–ù–ï–ò–ó–í–ï–°–¢–ù–û"

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –≤—Å–µ –æ—Ü–µ–Ω–∫–∏ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª–µ–π
    sorted_scores = sorted(all_scores)
    n = len(sorted_scores)

    # –ù–∞—Ö–æ–¥–∏–º –ø–æ–∑–∏—Ü–∏—é —Ç–µ–∫—É—â–µ–≥–æ —è–∑—ã–∫–∞
    position = sorted_scores.index(composite) if composite in sorted_scores else n // 2
    percentile = (position / n) * 100

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –ø–æ –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—é
    if percentile >= 90:
        category = "–û–ß–ï–ù–¨ –ö–†–£–ü–ù–´–ô"  # –¢–æ–ø 10%
    elif percentile >= 70:
        category = "–ö–†–£–ü–ù–´–ô"        # –¢–æ–ø 30%
    elif percentile >= 40:
        category = "–°–†–ï–î–ù–ò–ô"        # –°—Ä–µ–¥–Ω–∏–µ 30%
    elif percentile >= 20:
        category = "–ù–ï–ë–û–õ–¨–®–û–ô"      # –ù–∏–∂–Ω–∏–µ 20%
    else:
        category = "–ú–ò–ù–ò–ú–ê–õ–¨–ù–´–ô"    # –°–∞–º—ã–µ –º–∞–ª–µ–Ω—å–∫–∏–µ 20%

    return round(composite, 1), category


def get_balanced_language_selection(metrics_data: Dict, min_projects: int = 10):
    """
    –í—ã–±–∏—Ä–∞–µ—Ç —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫—É —è–∑—ã–∫–æ–≤ –∏–∑ –≤—Å–µ—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
    """
    composite_scores = []
    all_composite_scores = []

    # –°–Ω–∞—á–∞–ª–∞ —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –æ—Ü–µ–Ω–∫–∏ –¥–ª—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    for lang in set().union(*[set(data.keys()) for data in metrics_data.values()]):
        if all(lang in metrics_data[metric] for metric in ['stars', 'forks', 'issues']):
            stars_vals = metrics_data['stars'][lang]
            forks_vals = metrics_data['forks'][lang]
            issues_vals = metrics_data['issues'][lang]

            if len(stars_vals) >= min_projects:
                stars_med = median(stars_vals)
                forks_med = median(forks_vals)
                issues_med = median(issues_vals)

                # –í—Ä–µ–º–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª–µ–π
                temp_composite = (stars_med * 0.4 + forks_med * 0.35 + issues_med * 0.25)
                all_composite_scores.append(temp_composite)

    # –¢–µ–ø–µ—Ä—å –≤—ã—á–∏—Å–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏ —Å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π
    for lang in set().union(*[set(data.keys()) for data in metrics_data.values()]):
        if all(lang in metrics_data[metric] for metric in ['stars', 'forks', 'issues']):
            stars_vals = metrics_data['stars'][lang]
            forks_vals = metrics_data['forks'][lang]
            issues_vals = metrics_data['issues'][lang]

            if len(stars_vals) >= min_projects:
                stars_med = median(stars_vals)
                forks_med = median(forks_vals)
                issues_med = median(issues_vals)

                # –ò–°–ü–û–õ–¨–ó–£–ï–ú –û–¢–ù–û–°–ò–¢–ï–õ–¨–ù–£–Æ –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Æ
                composite, category = calculate_relative_composite_score(
                    stars_med, forks_med, issues_med, all_composite_scores
                )
                project_count = len(stars_vals)

                composite_scores.append((lang, composite, stars_med, forks_med, issues_med, project_count, category))

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é –æ—Ü–µ–Ω–∫–∏
    composite_scores.sort(key=lambda x: x[1], reverse=True)

    # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    very_large = [lang for lang in composite_scores if lang[6] == "–û–ß–ï–ù–¨ –ö–†–£–ü–ù–´–ô"]
    large = [lang for lang in composite_scores if lang[6] == "–ö–†–£–ü–ù–´–ô"]
    medium = [lang for lang in composite_scores if lang[6] == "–°–†–ï–î–ù–ò–ô"]
    small = [lang for lang in composite_scores if lang[6] == "–ù–ï–ë–û–õ–¨–®–û–ô"]
    minimal = [lang for lang in composite_scores if lang[6] == "–ú–ò–ù–ò–ú–ê–õ–¨–ù–´–ô"]

    logger.info(f"üìä –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú:")
    logger.info(f"  –û–ß–ï–ù–¨ –ö–†–£–ü–ù–´–ï: {len(very_large)} —è–∑—ã–∫–æ–≤")
    logger.info(f"  –ö–†–£–ü–ù–´–ï: {len(large)} —è–∑—ã–∫–æ–≤")
    logger.info(f"  –°–†–ï–î–ù–ò–ï: {len(medium)} —è–∑—ã–∫–æ–≤")
    logger.info(f"  –ù–ï–ë–û–õ–¨–®–ò–ï: {len(small)} —è–∑—ã–∫–æ–≤")
    logger.info(f"  –ú–ò–ù–ò–ú–ê–õ–¨–ù–´–ï: {len(minimal)} —è–∑—ã–∫–æ–≤")

    # –í—ã–±–∏—Ä–∞–µ–º –ø–æ 3 —è–∑—ã–∫–∞ –∏–∑ –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
    balanced_selection = []

    # –û–ß–ï–ù–¨ –ö–†–£–ü–ù–´–ï - –±–µ—Ä–µ–º –≤—Å–µ –∏–ª–∏ –º–∞–∫—Å–∏–º—É–º 3
    balanced_selection.extend(very_large[:3])

    # –ö–†–£–ü–ù–´–ï - –±–µ—Ä–µ–º –º–∞–∫—Å–∏–º—É–º 3
    balanced_selection.extend(large[:3])

    # –°–†–ï–î–ù–ò–ï - –±–µ—Ä–µ–º –º–∞–∫—Å–∏–º—É–º 3
    balanced_selection.extend(medium[:3])

    # –ù–ï–ë–û–õ–¨–®–ò–ï - –±–µ—Ä–µ–º –º–∞–∫—Å–∏–º—É–º 3
    balanced_selection.extend(small[:3])

    # –ú–ò–ù–ò–ú–ê–õ–¨–ù–´–ï - –±–µ—Ä–µ–º –º–∞–∫—Å–∏–º—É–º 3
    balanced_selection.extend(minimal[:3])

    # –ï—Å–ª–∏ –≤ –∫–∞–∫–∏—Ö-—Ç–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö –Ω–µ—Ç —è–∑—ã–∫–æ–≤, –¥–æ–±–∏—Ä–∞–µ–º –∏–∑ –¥—Ä—É–≥–∏—Ö
    if len(balanced_selection) < 10:
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ø–æ–≤—ã–µ —è–∑—ã–∫–∏ –∏–∑ –æ–±—â–µ–≥–æ —Å–ø–∏—Å–∫–∞
        for lang_data in composite_scores:
            if lang_data not in balanced_selection and len(balanced_selection) < 15:
                balanced_selection.append(lang_data)

    logger.info(f"üìã –í–´–ë–û–†–ö–ê –î–õ–Ø –ì–†–ê–§–ò–ö–ê: {len(balanced_selection)} —è–∑—ã–∫–æ–≤")
    return balanced_selection


def create_balanced_chart(metric_results: List[Tuple], output_path: str):
    """–°–æ–∑–¥–∞–µ—Ç —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º"""

    if not metric_results:
        logger.error("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞")
        return None

    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞
    labels = []
    values = []

    for lang, composite, stars, forks, issues, count, category in metric_results:
        # –°–æ–∑–¥–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—É—é –º–µ—Ç–∫—É
        label = f"{lang} ({category})"
        labels.append(label)
        values.append(composite)

    # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ–∏–∫
    result_path = barh_chart(
        labels=labels,
        values=values,
        out_path=output_path,
        title="–ê–Ω–∞–ª–∏–∑ –º–∞—Å—à—Ç–∞–±–∞ –ø—Ä–æ–µ–∫—Ç–æ–≤ –ø–æ —è–∑—ã–∫–∞–º –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è",
        xlabel="–ö–æ–º–ø–æ–∑–∏—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –º–∞—Å—à—Ç–∞–±–∞",
        ylabel="–Ø–∑—ã–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è"
    )

    return result_path


def main():
    parser = argparse.ArgumentParser(
        description="–ê–Ω–∞–ª–∏–∑ –º–∞—Å—à—Ç–∞–±–∞ –ø—Ä–æ–µ–∫—Ç–æ–≤ –ø–æ —è–∑—ã–∫–∞–º –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è"
    )
    parser.add_argument(
        "--min-projects",
        type=int,
        default=10,
        help="–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–µ–∫—Ç–æ–≤ –¥–ª—è —è–∑—ã–∫–∞"
    )
    parser.add_argument(
        "--out",
        type=str,
        default="/app/outputs/project_scale_analysis.png",
        help="–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞"
    )

    args = parser.parse_args()

    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –º–∞—Å—à—Ç–∞–± –ø—Ä–æ–µ–∫—Ç–æ–≤
    metrics_data = analyze_project_scale()

    # –ü–æ–ª—É—á–∞–µ–º —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫—É
    logger.info("üìä –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏...")
    balanced_selection = get_balanced_language_selection(metrics_data, args.min_projects)

    # –°–æ–∑–¥–∞–µ–º —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫
    balanced_path = create_balanced_chart(balanced_selection, args.out)

    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    logger.info(f"\nüéØ –ê–ù–ê–õ–ò–ó –ú–ê–°–®–¢–ê–ë–ê –ü–†–û–ï–ö–¢–û–í (–û–¢–ù–û–°–ò–¢–ï–õ–¨–ù–ê–Ø –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø)")
    logger.info("=" * 80)

    logger.info("üìä –õ–ï–ì–ï–ù–î–ê –ö–ê–¢–ï–ì–û–†–ò–ô:")
    logger.info("  –û–ß–ï–ù–¨ –ö–†–£–ü–ù–´–ô - –¢–æ–ø 10% —è–∑—ã–∫–æ–≤ –ø–æ –º–∞—Å—à—Ç–∞–±—É –ø—Ä–æ–µ–∫—Ç–æ–≤")
    logger.info("  –ö–†–£–ü–ù–´–ô - –°–ª–µ–¥—É—é—â–∏–µ 20% (—Ç–æ–ø 11-30%)")
    logger.info("  –°–†–ï–î–ù–ò–ô - –°—Ä–µ–¥–Ω–∏–µ 30% (31-60%)")
    logger.info("  –ù–ï–ë–û–õ–¨–®–û–ô - –°–ª–µ–¥—É—é—â–∏–µ 20% (61-80%)")
    logger.info("  –ú–ò–ù–ò–ú–ê–õ–¨–ù–´–ô - –ù–∏–∂–Ω–∏–µ 20% (81-100%)")
    logger.info("")

    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –¥–ª—è –≤—ã–≤–æ–¥–∞
    categories = {}
    for lang_data in balanced_selection:
        category = lang_data[6]
        if category not in categories:
            categories[category] = []
        categories[category].append(lang_data)

    # –í—ã–≤–æ–¥–∏–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    for category_name in ["–û–ß–ï–ù–¨ –ö–†–£–ü–ù–´–ô", "–ö–†–£–ü–ù–´–ô", "–°–†–ï–î–ù–ò–ô", "–ù–ï–ë–û–õ–¨–®–û–ô", "–ú–ò–ù–ò–ú–ê–õ–¨–ù–´–ô"]:
        if category_name in categories and categories[category_name]:
            logger.info(f"\n{category_name}:")
            for lang, composite, stars, forks, issues, count, _ in categories[category_name]:
                logger.info(f"  {lang:<15} {composite:5.1f} | Stars:{stars:4.0f} Forks:{forks:3.0f} Issues:{issues:3.0f} (n={count})")

    logger.info(f"\n‚úÖ –ì–†–ê–§–ò–ö –°–û–•–†–ê–ù–ï–ù: {balanced_path}")
    logger.info("üéØ –ê–Ω–∞–ª–∏–∑ –º–∞—Å—à—Ç–∞–±–∞ –ø—Ä–æ–µ–∫—Ç–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω!")


if __name__ == "__main__":
    main()
